{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dd0 Cell Density</th>\n",
       "      <th>dd0-dd1 Cell Density Gradient</th>\n",
       "      <th>dd1 Cell Density</th>\n",
       "      <th>dd1-dd2 Cell Density Gradient</th>\n",
       "      <th>dd2 Cell Density</th>\n",
       "      <th>dd2-dd3 Cell Density Gradient</th>\n",
       "      <th>dd3 Cell Density</th>\n",
       "      <th>dd3-dd5 Cell Density Gradient</th>\n",
       "      <th>dd5 Cell Density</th>\n",
       "      <th>dd5-dd7 Cell Density Gradient</th>\n",
       "      <th>...</th>\n",
       "      <th>dd1 Lactate Concentration</th>\n",
       "      <th>dd3 Lactate Concentration</th>\n",
       "      <th>dd5 Lactate Concentration</th>\n",
       "      <th>dd7 Lactate Concentration</th>\n",
       "      <th>dd0 Glucose Concentration</th>\n",
       "      <th>dd1 Glucose Concentration</th>\n",
       "      <th>dd3 Glucose Concentration</th>\n",
       "      <th>dd5 Glucose Concentration</th>\n",
       "      <th>dd7 Glucose Concentration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.213793</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.19007</td>\n",
       "      <td>1.047261</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.810945</td>\n",
       "      <td>1.820</td>\n",
       "      <td>-0.144394</td>\n",
       "      <td>...</td>\n",
       "      <td>14.025</td>\n",
       "      <td>2.090</td>\n",
       "      <td>17.780</td>\n",
       "      <td>5.935</td>\n",
       "      <td>9.1800</td>\n",
       "      <td>3.895</td>\n",
       "      <td>9.8750</td>\n",
       "      <td>0.635</td>\n",
       "      <td>7.555</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.19007</td>\n",
       "      <td>1.071063</td>\n",
       "      <td>0.246426</td>\n",
       "      <td>1.335</td>\n",
       "      <td>0.749064</td>\n",
       "      <td>2.335</td>\n",
       "      <td>-0.144394</td>\n",
       "      <td>...</td>\n",
       "      <td>13.350</td>\n",
       "      <td>2.165</td>\n",
       "      <td>17.105</td>\n",
       "      <td>12.510</td>\n",
       "      <td>9.5200</td>\n",
       "      <td>4.470</td>\n",
       "      <td>10.1450</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.910</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.19007</td>\n",
       "      <td>1.071063</td>\n",
       "      <td>-0.038338</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>1.660</td>\n",
       "      <td>-0.144394</td>\n",
       "      <td>...</td>\n",
       "      <td>13.670</td>\n",
       "      <td>1.775</td>\n",
       "      <td>19.050</td>\n",
       "      <td>7.210</td>\n",
       "      <td>9.0275</td>\n",
       "      <td>4.415</td>\n",
       "      <td>10.2700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.745</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.19007</td>\n",
       "      <td>1.273374</td>\n",
       "      <td>-0.462059</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.510949</td>\n",
       "      <td>1.035</td>\n",
       "      <td>-0.144394</td>\n",
       "      <td>...</td>\n",
       "      <td>11.955</td>\n",
       "      <td>0.995</td>\n",
       "      <td>16.430</td>\n",
       "      <td>14.295</td>\n",
       "      <td>8.9950</td>\n",
       "      <td>5.155</td>\n",
       "      <td>10.2550</td>\n",
       "      <td>2.270</td>\n",
       "      <td>2.135</td>\n",
       "      <td>57.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19007</td>\n",
       "      <td>0.963956</td>\n",
       "      <td>1.778134</td>\n",
       "      <td>2.678</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>2.670</td>\n",
       "      <td>-0.376404</td>\n",
       "      <td>...</td>\n",
       "      <td>11.300</td>\n",
       "      <td>15.100</td>\n",
       "      <td>16.425</td>\n",
       "      <td>14.455</td>\n",
       "      <td>9.5475</td>\n",
       "      <td>1.700</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>1.610</td>\n",
       "      <td>1.065</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dd0 Cell Density  dd0-dd1 Cell Density Gradient  dd1 Cell Density  \\\n",
       "0             0.725                       0.213793              0.88   \n",
       "1             0.650                       0.384615              0.90   \n",
       "2             0.880                       0.022727              0.90   \n",
       "3             0.785                       0.363057              1.07   \n",
       "4             0.410                       0.975610              0.81   \n",
       "\n",
       "   dd1-dd2 Cell Density Gradient  dd2 Cell Density  \\\n",
       "0                        0.19007          1.047261   \n",
       "1                        0.19007          1.071063   \n",
       "2                        0.19007          1.071063   \n",
       "3                        0.19007          1.273374   \n",
       "4                        0.19007          0.963956   \n",
       "\n",
       "   dd2-dd3 Cell Density Gradient  dd3 Cell Density   \\\n",
       "0                      -0.040354              1.005   \n",
       "1                       0.246426              1.335   \n",
       "2                      -0.038338              1.030   \n",
       "3                      -0.462059              0.685   \n",
       "4                       1.778134              2.678   \n",
       "\n",
       "   dd3-dd5 Cell Density Gradient  dd5 Cell Density  \\\n",
       "0                       0.810945             1.820   \n",
       "1                       0.749064             2.335   \n",
       "2                       0.611650             1.660   \n",
       "3                       0.510949             1.035   \n",
       "4                      -0.002987             2.670   \n",
       "\n",
       "   dd5-dd7 Cell Density Gradient  ...  dd1 Lactate Concentration  \\\n",
       "0                      -0.144394  ...                     14.025   \n",
       "1                      -0.144394  ...                     13.350   \n",
       "2                      -0.144394  ...                     13.670   \n",
       "3                      -0.144394  ...                     11.955   \n",
       "4                      -0.376404  ...                     11.300   \n",
       "\n",
       "   dd3 Lactate Concentration  dd5 Lactate Concentration  \\\n",
       "0                      2.090                     17.780   \n",
       "1                      2.165                     17.105   \n",
       "2                      1.775                     19.050   \n",
       "3                      0.995                     16.430   \n",
       "4                     15.100                     16.425   \n",
       "\n",
       "   dd7 Lactate Concentration  dd0 Glucose Concentration  \\\n",
       "0                      5.935                     9.1800   \n",
       "1                     12.510                     9.5200   \n",
       "2                      7.210                     9.0275   \n",
       "3                     14.295                     8.9950   \n",
       "4                     14.455                     9.5475   \n",
       "\n",
       "   dd1 Glucose Concentration  dd3 Glucose Concentration  \\\n",
       "0                      3.895                     9.8750   \n",
       "1                      4.470                    10.1450   \n",
       "2                      4.415                    10.2700   \n",
       "3                      5.155                    10.2550   \n",
       "4                      1.700                     0.0175   \n",
       "\n",
       "   dd5 Glucose Concentration  dd7 Glucose Concentration     y  \n",
       "0                      0.635                      7.555  75.7  \n",
       "1                      1.010                      2.910  75.0  \n",
       "2                      0.000                      6.745  55.6  \n",
       "3                      2.270                      2.135  57.7  \n",
       "4                      1.610                      1.065  63.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from functions import clean_column_names, Classifier_calculate_metrics_FINAL2, load_and_prepare_data, select_features_by_pearson, select_features_by_anova, get_dataframe_with_selected_features\n",
    "\n",
    "X, y = load_and_prepare_data()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the percentage of sufficient experiences (for XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sufficient_samples = X[X['y'] >= 90].shape[0]\n",
    "num_insuff_samples = X.shape[0] - num_sufficient_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature selection using correlation coefficients\n",
    "\n",
    "Feature Selection with correlation coefficients:\n",
    "\n",
    "- Pearson: input var numerical, output var numerical (regression problem)\n",
    "- ANOVA: input var numerical, output var categorical (classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation:\n",
      "Number of variables with p-value <= 0.005: 9\n",
      "ANOVA correlation:\n",
      "Number of variables with p-value <= 0.05: 15\n"
     ]
    }
   ],
   "source": [
    "# Pearson\n",
    "print('Pearson correlation:')\n",
    "cols_PearsonCorr = select_features_by_pearson(X)\n",
    "\n",
    "# ANOVA\n",
    "print('ANOVA correlation:')\n",
    "cols_ANOVACorr = select_features_by_anova(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Definition of feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definition of datasets with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set from study by Williams et al. (2020)\n",
    "X_FS1_RF = get_dataframe_with_selected_features(X=X, feature_set_name='FS1_RF')\n",
    "\n",
    "# Feature sets obtained with biclustering analysis\n",
    "X_CCCB1 = get_dataframe_with_selected_features(X=X, feature_set_name='CCCB1')\n",
    "X_CCCB1_1 = get_dataframe_with_selected_features(X=X, feature_set_name='CCCB1_1')\n",
    "\n",
    "X_CCCB2 = get_dataframe_with_selected_features(X=X, feature_set_name='CCCB2')\n",
    "X_CCCB2_1 = get_dataframe_with_selected_features(X=X, feature_set_name='CCCB2_1')\n",
    "\n",
    "# Feature sets obtained with correlation coefficients\n",
    "X_PearsonCorr = X[cols_PearsonCorr]\n",
    "X_ANOVACorr = X[cols_ANOVACorr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most selected features (across all feature sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,6))\n",
    "\n",
    "features = ['dd5 CD', 'dd1 CD', 'dd2 CD', 'dd7 CD', 'Av. DO \\n concentration dd0', \n",
    "            'DO gradient/CC dd2', 'dd2 Av. pH', 'dd3 CD']  \n",
    "number_of_times_chosen = [6,5,5,5,5,5,5,4]\n",
    "bar_colors = ['green', 'green', 'green', 'green', 'orange', 'orange', 'blue', 'green']\n",
    "\n",
    "ax.bar(features, number_of_times_chosen, color=bar_colors,width=0.4)\n",
    "ax.set_title('#Times the feature is chosen', fontsize = 14)\n",
    "ax.set_xlabel('Features', fontsize =14)\n",
    "ax.set_ylim(0,7)\n",
    "ax.set_xticks(features)\n",
    "ax.set_xticklabels(features, fontsize=14, rotation=45) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common for all classification models\n",
    "cv1 = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "cv2 = LeaveOneOut()\n",
    "\n",
    "CV_methods_list = [cv1, cv2]\n",
    "CV_methods_strings_list = ['Stratified 10-Fold', 'Leave One Out']\n",
    "CV_methods_strings = ['skfcv', 'loocv']\n",
    "\n",
    "threshold_for_classification = 90\n",
    "y1 = y.values.ravel()\n",
    "y_class = y_class = np.where(y1 >= threshold_for_classification, 0, 1)\n",
    "\n",
    "FSs = [X_FS1_RF, X_CCCB1, X_CCCB1_1, X_CCCB2, X_CCCB2_1, X_ANOVACorr]\n",
    "FSs_strings = ['X_FS1_RF', 'X_CCCB1', 'X_CCCB1_1', 'X_CCCB2', 'X_CCCB2_1', 'X_ANOVACorr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Gaussian Naive Bayes Classifier\n",
    "- without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier Results\n",
      "Stratified 10-Fold\n",
      "Using the feature selection  X_FS1_RF\n",
      "Mean accuracy: 0.683 Â± 0.203\n",
      "Mean precision: 0.792 Â± 0.180\n",
      "Mean recall: 0.750 Â± 0.224\n",
      "Mean f1 score: 0.752 Â± 0.166\n",
      "Mean MCC score: 0.296 Â± 0.468\n",
      "Mean AIC score: 150.820 Â± 55.398\n",
      "Mean BIC score: 139.783 Â± 55.398\n",
      "\n",
      "Using the feature selection  X_CCCB1\n",
      "Mean accuracy: 0.567 Â± 0.153\n",
      "Mean precision: 0.860 Â± 0.215\n",
      "Mean recall: 0.490 Â± 0.161\n",
      "Mean f1 score: 0.600 Â± 0.145\n",
      "Mean MCC score: 0.227 Â± 0.399\n",
      "Mean AIC score: 134.548 Â± 26.593\n",
      "Mean BIC score: 123.511 Â± 26.593\n",
      "\n",
      "Using the feature selection  X_CCCB1_1\n",
      "Mean accuracy: 0.533 Â± 0.180\n",
      "Mean precision: 0.718 Â± 0.214\n",
      "Mean recall: 0.530 Â± 0.182\n",
      "Mean f1 score: 0.597 Â± 0.171\n",
      "Mean MCC score: 0.061 Â± 0.398\n",
      "Mean AIC score: 238.972 Â± 44.409\n",
      "Mean BIC score: 219.605 Â± 44.409\n",
      "\n",
      "Using the feature selection  X_CCCB2\n",
      "Mean accuracy: 0.633 Â± 0.208\n",
      "Mean precision: 0.833 Â± 0.211\n",
      "Mean recall: 0.580 Â± 0.200\n",
      "Mean f1 score: 0.672 Â± 0.188\n",
      "Mean MCC score: 0.309 Â± 0.448\n",
      "Mean AIC score: 147.100 Â± 27.074\n",
      "Mean BIC score: 134.397 Â± 27.074\n",
      "\n",
      "Using the feature selection  X_CCCB2_1\n",
      "Mean accuracy: 0.583 Â± 0.154\n",
      "Mean precision: 0.750 Â± 0.183\n",
      "Mean recall: 0.610 Â± 0.197\n",
      "Mean f1 score: 0.655 Â± 0.152\n",
      "Mean MCC score: 0.140 Â± 0.345\n",
      "Mean AIC score: 266.551 Â± 41.681\n",
      "Mean BIC score: 243.853 Â± 41.681\n",
      "\n",
      "Using the feature selection  X_ANOVACorr\n",
      "Mean accuracy: 0.733 Â± 0.153\n",
      "Mean precision: 0.967 Â± 0.100\n",
      "Mean recall: 0.630 Â± 0.205\n",
      "Mean f1 score: 0.743 Â± 0.171\n",
      "Mean MCC score: 0.557 Â± 0.254\n",
      "Mean AIC score: 148.817 Â± 24.121\n",
      "Mean BIC score: 136.114 Â± 24.121\n",
      "\n",
      "Leave One Out\n",
      "Using the feature selection  X_FS1_RF\n",
      "Accuracy: 0.700\n",
      "Precision: 0.811\n",
      "Recall: 0.732\n",
      "f1 score: 0.769\n",
      "MCC score: 0.348\n",
      "Mean AIC score: 109.775 Â± 11.717\n",
      "Mean BIC score: 3.775 Â± 11.717\n",
      "\n",
      "Using the feature selection  X_CCCB1\n",
      "Accuracy: 0.583\n",
      "Precision: 0.833\n",
      "Recall: 0.488\n",
      "f1 score: 0.615\n",
      "MCC score: 0.263\n",
      "Mean AIC score: 109.911 Â± 9.627\n",
      "Mean BIC score: 3.911 Â± 9.627\n",
      "\n",
      "Using the feature selection  X_CCCB1_1\n",
      "Accuracy: 0.567\n",
      "Precision: 0.759\n",
      "Recall: 0.537\n",
      "f1 score: 0.629\n",
      "MCC score: 0.157\n",
      "Mean AIC score: 194.102 Â± 16.086\n",
      "Mean BIC score: 8.102 Â± 16.086\n",
      "\n",
      "Using the feature selection  X_CCCB2\n",
      "Accuracy: 0.650\n",
      "Precision: 0.857\n",
      "Recall: 0.585\n",
      "f1 score: 0.696\n",
      "MCC score: 0.350\n",
      "Mean AIC score: 125.268 Â± 9.586\n",
      "Mean BIC score: 3.268 Â± 9.586\n",
      "\n",
      "Using the feature selection  X_CCCB2_1\n",
      "Accuracy: 0.633\n",
      "Precision: 0.806\n",
      "Recall: 0.610\n",
      "f1 score: 0.694\n",
      "MCC score: 0.274\n",
      "Mean AIC score: 225.095 Â± 15.892\n",
      "Mean BIC score: 7.095 Â± 15.892\n",
      "\n",
      "Using the feature selection  X_ANOVACorr\n",
      "Accuracy: 0.717\n",
      "Precision: 0.962\n",
      "Recall: 0.610\n",
      "f1 score: 0.746\n",
      "MCC score: 0.523\n",
      "Mean AIC score: 126.496 Â± 8.900\n",
      "Mean BIC score: 4.496 Â± 8.900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AICs_LOO_GNB = []\n",
    "\n",
    "print('Gaussian Naive Bayes Classifier Results')\n",
    "print('Stratified 10-Fold')\n",
    "for i in range(len(FSs)):\n",
    "    print('Using the feature selection ', FSs_strings[i])\n",
    "    (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'GaussianNaiveBayesClassifier',\n",
    "                                                                                X = FSs[i], \n",
    "                                                                                y = y_class,\n",
    "                                                                                model_params={},\n",
    "                                                                                cross_validation_technique = 'skfcv')\n",
    "    print()\n",
    "\n",
    "print('Leave One Out')\n",
    "for i in range(len(FSs)):\n",
    "    print('Using the feature selection ', FSs_strings[i])\n",
    "    (metrics, stds) = Classifier_calculate_metrics_FINAL2(model_str = 'GaussianNaiveBayesClassifier',\n",
    "                                                                                X = FSs[i], \n",
    "                                                                                y = y_class,\n",
    "                                                                                model_params={},\n",
    "                                                                                cross_validation_technique = 'loocv')\n",
    "    AICs_LOO_GNB.append(metrics[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE + Gaussian Naive Bayes Classifier Results\n",
      "Stratified 10-Fold\n",
      "Using the feature selection  X_FS1_RF\n",
      "Mean accuracy: 0.617 Â± 0.183\n",
      "Mean precision: 0.808 Â± 0.217\n",
      "Mean recall: 0.610 Â± 0.197\n",
      "Mean f1 score: 0.678 Â± 0.163\n",
      "Mean MCC score: 0.240 Â± 0.410\n",
      "Mean AIC score: 152.352 Â± 56.511\n",
      "Mean BIC score: 141.315 Â± 56.511\n",
      "\n",
      "Using the feature selection  X_CCCB1\n",
      "Mean accuracy: 0.567 Â± 0.153\n",
      "Mean precision: 0.833 Â± 0.211\n",
      "Mean recall: 0.510 Â± 0.116\n",
      "Mean f1 score: 0.615 Â± 0.127\n",
      "Mean MCC score: 0.197 Â± 0.408\n",
      "Mean AIC score: 138.581 Â± 27.101\n",
      "Mean BIC score: 127.544 Â± 27.101\n",
      "\n",
      "Using the feature selection  X_CCCB1_1\n",
      "Mean accuracy: 0.533 Â± 0.208\n",
      "Mean precision: 0.710 Â± 0.236\n",
      "Mean recall: 0.555 Â± 0.193\n",
      "Mean f1 score: 0.610 Â± 0.184\n",
      "Mean MCC score: 0.040 Â± 0.459\n",
      "Mean AIC score: 244.459 Â± 45.584\n",
      "Mean BIC score: 225.093 Â± 45.584\n",
      "\n",
      "Using the feature selection  X_CCCB2\n",
      "Mean accuracy: 0.683 Â± 0.174\n",
      "Mean precision: 0.875 Â± 0.172\n",
      "Mean recall: 0.650 Â± 0.200\n",
      "Mean f1 score: 0.725 Â± 0.147\n",
      "Mean MCC score: 0.346 Â± 0.402\n",
      "Mean AIC score: 149.678 Â± 26.792\n",
      "Mean BIC score: 136.975 Â± 26.792\n",
      "\n",
      "Using the feature selection  X_CCCB2_1\n",
      "Mean accuracy: 0.633 Â± 0.163\n",
      "Mean precision: 0.792 Â± 0.180\n",
      "Mean recall: 0.655 Â± 0.169\n",
      "Mean f1 score: 0.703 Â± 0.137\n",
      "Mean MCC score: 0.230 Â± 0.379\n",
      "Mean AIC score: 270.799 Â± 46.083\n",
      "Mean BIC score: 248.101 Â± 46.083\n",
      "\n",
      "Using the feature selection  X_ANOVACorr\n",
      "Mean accuracy: 0.717 Â± 0.183\n",
      "Mean precision: 0.930 Â± 0.155\n",
      "Mean recall: 0.655 Â± 0.232\n",
      "Mean f1 score: 0.739 Â± 0.181\n",
      "Mean MCC score: 0.500 Â± 0.375\n",
      "Mean AIC score: 150.733 Â± 24.316\n",
      "Mean BIC score: 138.031 Â± 24.316\n",
      "\n",
      "Leave One Out\n",
      "Using the feature selection  X_FS1_RF\n",
      "Accuracy: 0.617\n",
      "Precision: 0.821\n",
      "Recall: 0.561\n",
      "f1 score: 0.667\n",
      "MCC score: 0.278\n",
      "Mean AIC score: 110.171 Â± 10.794\n",
      "Mean BIC score: 4.171 Â± 10.794\n",
      "\n",
      "Using the feature selection  X_CCCB1\n",
      "Accuracy: 0.600\n",
      "Precision: 0.815\n",
      "Recall: 0.537\n",
      "f1 score: 0.647\n",
      "MCC score: 0.256\n",
      "Mean AIC score: 110.235 Â± 9.904\n",
      "Mean BIC score: 4.235 Â± 9.904\n",
      "\n",
      "Using the feature selection  X_CCCB1_1\n",
      "Accuracy: 0.550\n",
      "Precision: 0.719\n",
      "Recall: 0.561\n",
      "f1 score: 0.630\n",
      "MCC score: 0.081\n",
      "Mean AIC score: 195.364 Â± 17.329\n",
      "Mean BIC score: 9.364 Â± 17.329\n",
      "\n",
      "Using the feature selection  X_CCCB2\n",
      "Accuracy: 0.717\n",
      "Precision: 0.900\n",
      "Recall: 0.659\n",
      "f1 score: 0.761\n",
      "MCC score: 0.466\n",
      "Mean AIC score: 125.542 Â± 9.822\n",
      "Mean BIC score: 3.542 Â± 9.822\n",
      "\n",
      "Using the feature selection  X_CCCB2_1\n",
      "Accuracy: 0.617\n",
      "Precision: 0.781\n",
      "Recall: 0.610\n",
      "f1 score: 0.685\n",
      "MCC score: 0.225\n",
      "Mean AIC score: 226.159 Â± 16.456\n",
      "Mean BIC score: 8.159 Â± 16.456\n",
      "\n",
      "Using the feature selection  X_ANOVACorr\n",
      "Accuracy: 0.700\n",
      "Precision: 0.897\n",
      "Recall: 0.634\n",
      "f1 score: 0.743\n",
      "MCC score: 0.443\n",
      "Mean AIC score: 126.867 Â± 9.547\n",
      "Mean BIC score: 4.867 Â± 9.547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AICs_LOO_SMOTE_GNB = []\n",
    "\n",
    "print('SMOTE + Gaussian Naive Bayes Classifier Results')\n",
    "print('Stratified 10-Fold')\n",
    "for i in range(len(FSs)):\n",
    "    print('Using the feature selection ', FSs_strings[i])\n",
    "    (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'SMOTE+GaussinNaiveBayesClassifier',\n",
    "                                                                                X = FSs[i], \n",
    "                                                                                y = y_class,\n",
    "                                                                                model_params={},\n",
    "                                                                                cross_validation_technique = 'skfcv')\n",
    "    print()\n",
    "\n",
    "print('Leave One Out')\n",
    "for i in range(len(FSs)):\n",
    "    print('Using the feature selection ', FSs_strings[i])\n",
    "    (metrics, stds) = Classifier_calculate_metrics_FINAL2(model_str = 'SMOTE+GaussinNaiveBayesClassifier',\n",
    "                                                                                X = FSs[i], \n",
    "                                                                                y = y_class,\n",
    "                                                                                model_params={},\n",
    "                                                                                cross_validation_technique = 'loocv')\n",
    "    AICs_LOO_SMOTE_GNB.append(metrics[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.7667\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15, 'n_estimators': 3}\n",
      "Best Cross-Validation Accuracy: 0.8333\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 20, 'n_estimators': 3}\n",
      "Best Cross-Validation Accuracy: 0.8167\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best Cross-Validation Accuracy: 0.9167\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [3, 4, 5, 10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 8, 10, 20],\n",
    "    'min_samples_split': [2, 5, 8, 10, 15, 20]\n",
    "}\n",
    "\n",
    "best_hyperparameters_RFC_list = []\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_RFC_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Mean accuracy: 0.883 Â± 0.107\n",
      "Mean precision: 0.900 Â± 0.100\n",
      "Mean recall: 0.950 Â± 0.150\n",
      "Mean f1 score: 0.911 Â± 0.097\n",
      "Mean MCC score: 0.766 Â± 0.195\n",
      "Mean AIC score: 3218.826 Â± 86.313\n",
      "Mean BIC score: 2884.163 Â± 77.264\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Mean accuracy: 0.783 Â± 0.107\n",
      "Mean precision: 0.795 Â± 0.116\n",
      "Mean recall: 0.950 Â± 0.100\n",
      "Mean f1 score: 0.856 Â± 0.068\n",
      "Mean MCC score: 0.449 Â± 0.339\n",
      "Mean AIC score: 566.768 Â± 14.276\n",
      "Mean BIC score: 508.461 Â± 12.772\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Mean accuracy: 0.767 Â± 0.170\n",
      "Mean precision: 0.783 Â± 0.142\n",
      "Mean recall: 0.900 Â± 0.229\n",
      "Mean f1 score: 0.823 Â± 0.172\n",
      "Mean MCC score: 0.462 Â± 0.378\n",
      "Mean AIC score: 1487.915 Â± 37.021\n",
      "Mean BIC score: 1333.651 Â± 33.085\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Mean accuracy: 0.883 Â± 0.107\n",
      "Mean precision: 0.895 Â± 0.106\n",
      "Mean recall: 0.950 Â± 0.100\n",
      "Mean f1 score: 0.916 Â± 0.079\n",
      "Mean MCC score: 0.749 Â± 0.236\n",
      "Mean AIC score: 1450.026 Â± 31.722\n",
      "Mean BIC score: 1299.614 Â± 28.323\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Mean accuracy: 0.900 Â± 0.082\n",
      "Mean precision: 0.900 Â± 0.100\n",
      "Mean recall: 0.975 Â± 0.075\n",
      "Mean f1 score: 0.930 Â± 0.058\n",
      "Mean MCC score: 0.787 Â± 0.175\n",
      "Mean AIC score: 1185.226 Â± 30.580\n",
      "Mean BIC score: 1062.384 Â± 27.297\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Mean accuracy: 0.850 Â± 0.117\n",
      "Mean precision: 0.875 Â± 0.103\n",
      "Mean recall: 0.925 Â± 0.160\n",
      "Mean f1 score: 0.886 Â± 0.103\n",
      "Mean MCC score: 0.691 Â± 0.231\n",
      "Mean AIC score: 3298.205 Â± 112.650\n",
      "Mean BIC score: 2955.295 Â± 100.775\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Accuracy: 0.883\n",
      "Precision: 0.854\n",
      "Recall: 1.000\n",
      "f1 score: 0.921\n",
      "MCC score: 0.734\n",
      "Mean AIC score: 722.782 Â± 16.805\n",
      "Mean BIC score: 0.782 Â± 0.729\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Accuracy: 0.833\n",
      "Precision: 0.816\n",
      "Recall: 0.976\n",
      "f1 score: 0.889\n",
      "MCC score: 0.603\n",
      "Mean AIC score: 29.114 Â± 9.648\n",
      "Mean BIC score: 2.148 Â± 9.152\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Accuracy: 0.817\n",
      "Precision: 0.812\n",
      "Recall: 0.951\n",
      "f1 score: 0.876\n",
      "MCC score: 0.555\n",
      "Mean AIC score: 20.889 Â± 2.353\n",
      "Mean BIC score: 1.056 Â± 1.274\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Accuracy: 0.917\n",
      "Precision: 0.929\n",
      "Recall: 0.951\n",
      "f1 score: 0.940\n",
      "MCC score: 0.805\n",
      "Mean AIC score: 162.273 Â± 6.648\n",
      "Mean BIC score: 0.706 Â± 0.898\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Accuracy: 0.883\n",
      "Precision: 0.886\n",
      "Recall: 0.951\n",
      "f1 score: 0.918\n",
      "MCC score: 0.724\n",
      "Mean AIC score: 1726.779 Â± 25.354\n",
      "Mean BIC score: 0.946 Â± 1.009\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Accuracy: 0.850\n",
      "Precision: 0.848\n",
      "Recall: 0.951\n",
      "f1 score: 0.897\n",
      "MCC score: 0.641\n",
      "Mean AIC score: 1466.276 Â± 23.515\n",
      "Mean BIC score: 0.809 Â± 0.805\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AIC_LOO_RFC = []\n",
    "\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'RandomForestClassifier',\n",
    "                                                                                        X = FSs[i],\n",
    "                                                                                        y = y_class,\n",
    "                                                                                        model_params=best_hyperparameters_RFC_list[6*j+i],\n",
    "                                                                                        cross_validation_technique = CV_methods_strings[j])\n",
    "        if CV_methods_strings[j] == 'loocv':\n",
    "            AIC_LOO_RFC.append(mean_metrics[5])\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 0, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 1, 'scale_pos_weight': 1}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 3, 'reg_lambda': 1, 'scale_pos_weight': 1}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 10, 'reg_lambda': 0, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 50, 'reg_lambda': 0, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 4, 'reg_lambda': 0, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9167\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'reg_lambda': 0, 'scale_pos_weight': 1}\n",
      "Best Cross-Validation Accuracy: 0.8667\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 0, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.7500\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 50, 'reg_lambda': 0, 'scale_pos_weight': 1}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 1, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 1, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'reg_lambda': 1, 'scale_pos_weight': 2.1578947368421053}\n",
      "Best Cross-Validation Accuracy: 0.9167\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight_1 = num_insuff_samples/num_sufficient_samples\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [3, 4, 5, 10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'reg_lambda': [0,1],\n",
    "    'scale_pos_weight': [1, scale_pos_weight_1]\n",
    "}\n",
    "\n",
    "best_hyperparameters_XGBC_list = []\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        # Clean feature names\n",
    "        FSs[i] = clean_column_names(FSs[i])\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_XGBC_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Mean accuracy: 0.850 Â± 0.138\n",
      "Mean precision: 0.840 Â± 0.140\n",
      "Mean recall: 1.000 Â± 0.000\n",
      "Mean f1 score: 0.907 Â± 0.084\n",
      "Mean MCC score: 0.590 Â± 0.415\n",
      "Mean AIC score: 2731.211 Â± 341.928\n",
      "Mean BIC score: 2447.420 Â± 306.516\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Mean accuracy: 0.783 Â± 0.107\n",
      "Mean precision: 0.843 Â± 0.135\n",
      "Mean recall: 0.880 Â± 0.121\n",
      "Mean f1 score: 0.848 Â± 0.072\n",
      "Mean MCC score: 0.481 Â± 0.318\n",
      "Mean AIC score: 869.286 Â± 26.646\n",
      "Mean BIC score: 779.493 Â± 23.670\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Mean accuracy: 0.850 Â± 0.090\n",
      "Mean precision: 0.867 Â± 0.115\n",
      "Mean recall: 0.950 Â± 0.100\n",
      "Mean f1 score: 0.896 Â± 0.058\n",
      "Mean MCC score: 0.658 Â± 0.260\n",
      "Mean AIC score: 64.913 Â± 2.077\n",
      "Mean BIC score: 58.791 Â± 1.863\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Mean accuracy: 0.900 Â± 0.111\n",
      "Mean precision: 0.907 Â± 0.120\n",
      "Mean recall: 0.975 Â± 0.075\n",
      "Mean f1 score: 0.932 Â± 0.072\n",
      "Mean MCC score: 0.760 Â± 0.303\n",
      "Mean AIC score: 213.062 Â± 6.295\n",
      "Mean BIC score: 191.364 Â± 5.562\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Mean accuracy: 0.900 Â± 0.111\n",
      "Mean precision: 0.887 Â± 0.119\n",
      "Mean recall: 1.000 Â± 0.000\n",
      "Mean f1 score: 0.936 Â± 0.069\n",
      "Mean MCC score: 0.753 Â± 0.305\n",
      "Mean AIC score: 446.970 Â± 25.854\n",
      "Mean BIC score: 401.115 Â± 22.621\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Mean accuracy: 0.917 Â± 0.112\n",
      "Mean precision: 0.927 Â± 0.117\n",
      "Mean recall: 0.975 Â± 0.075\n",
      "Mean f1 score: 0.943 Â± 0.073\n",
      "Mean MCC score: 0.797 Â± 0.307\n",
      "Mean AIC score: 89.361 Â± 9.671\n",
      "Mean BIC score: 80.449 Â± 8.882\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Accuracy: 0.867\n",
      "Precision: 0.837\n",
      "Recall: 1.000\n",
      "f1 score: 0.911\n",
      "MCC score: 0.696\n",
      "Mean AIC score: 984.386 Â± 88.928\n",
      "Mean BIC score: 0.986 Â± 0.785\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Accuracy: 0.750\n",
      "Precision: 0.760\n",
      "Recall: 0.927\n",
      "f1 score: 0.835\n",
      "MCC score: 0.369\n",
      "Mean AIC score: 3432.333 Â± 238.048\n",
      "Mean BIC score: 1.267 Â± 1.447\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Accuracy: 0.850\n",
      "Precision: 0.864\n",
      "Recall: 0.927\n",
      "f1 score: 0.894\n",
      "MCC score: 0.643\n",
      "Mean AIC score: 471.775 Â± 8.802\n",
      "Mean BIC score: 1.108 Â± 2.069\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Accuracy: 0.900\n",
      "Precision: 0.872\n",
      "Recall: 1.000\n",
      "f1 score: 0.932\n",
      "MCC score: 0.773\n",
      "Mean AIC score: 2178.350 Â± 89.971\n",
      "Mean BIC score: 0.884 Â± 1.253\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Accuracy: 0.900\n",
      "Precision: 0.872\n",
      "Recall: 1.000\n",
      "f1 score: 0.932\n",
      "MCC score: 0.773\n",
      "Mean AIC score: 2179.578 Â± 79.401\n",
      "Mean BIC score: 0.911 Â± 1.300\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Accuracy: 0.917\n",
      "Precision: 0.891\n",
      "Recall: 1.000\n",
      "f1 score: 0.943\n",
      "MCC score: 0.810\n",
      "Mean AIC score: 1800.738 Â± 1.117\n",
      "Mean BIC score: 0.738 Â± 1.117\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CV_methods_strings = ['skfcv', 'loocv']\n",
    "AIC_LOO_XGBoost = []\n",
    "\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'XGBoostClassifier',\n",
    "                                                                                        X = FSs[i], \n",
    "                                                                                        y = y_class,\n",
    "                                                                                        model_params=best_hyperparameters_XGBC_list[6*j+i],\n",
    "                                                                                        cross_validation_technique = CV_methods_strings[j])\n",
    "        print()\n",
    "        if CV_methods_strings[j] == 'loocv':\n",
    "            AIC_LOO_XGBoost.append(mean_metrics[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Support Vector Machine Classifier\n",
    "\n",
    "- pipeline: (1) standard scaler, (2) SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier, pipeline = scaler, SVC\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svc__C': 1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7167\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7333\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.7000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.8167\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.7500\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.7333\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.8333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100, 1000],\n",
    "    'svc__kernel': ['linear','rbf'],\n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "best_hyperparameters_SVMC_list = []\n",
    "\n",
    "# Define scaler, model and pipeline\n",
    "standard_scaler = StandardScaler()\n",
    "model = SVC(random_state=42)\n",
    "pipeline_SVMC = Pipeline([\n",
    "    ('scaler', standard_scaler),\n",
    "    ('svc', model)\n",
    "])\n",
    "\n",
    "print('Support Vector Machine Classifier, pipeline = scaler, SVC')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=pipeline_SVMC, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_SVMC_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipeline: (1) SMOTE, (2) standard scaler, (3) SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier, pipeline = SMOTE, scaler, SVC\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8167\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svc__C': 1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7667\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7167\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svc__C': 1000, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7333\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svc__C': 0.1, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.6833\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8333\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svc__C': 1000, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svc__C': 1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7167\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svc__C': 1, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.7000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'svc__C': 100, 'svc__gamma': 1, 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Accuracy: 0.8167\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hyperparameters_SMOTE_SVMC_list = []\n",
    "\n",
    "# Define smote, scaler, model and pipeline\n",
    "SMOTE_SVM = SMOTE(random_state=42, k_neighbors=5)\n",
    "standard_scaler = StandardScaler()\n",
    "model = SVC(random_state=42)\n",
    "pipeline_SMOTE_SVMC = Pipeline([\n",
    "    ('smote', SMOTE_SVM),\n",
    "    ('scaler', standard_scaler),\n",
    "    ('svc', model)\n",
    "])\n",
    "\n",
    "print('Support Vector Machine Classifier, pipeline = SMOTE, scaler, SVC')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=pipeline_SMOTE_SVMC, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_SMOTE_SVMC_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the other classification evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier, pipeline = Scaler, SVC\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Mean accuracy: 0.717 Â± 0.183\n",
      "Mean precision: 0.738 Â± 0.149\n",
      "Mean recall: 0.925 Â± 0.160\n",
      "Mean f1 score: 0.814 Â± 0.134\n",
      "Mean MCC score: 0.238 Â± 0.463\n",
      "Mean AIC score: 98.647 Â± 3.717\n",
      "Mean BIC score: 89.173 Â± 3.477\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Mean accuracy: 0.800 Â± 0.145\n",
      "Mean precision: 0.820 Â± 0.130\n",
      "Mean recall: 0.925 Â± 0.160\n",
      "Mean f1 score: 0.858 Â± 0.115\n",
      "Mean MCC score: 0.524 Â± 0.368\n",
      "Mean AIC score: 73.210 Â± 5.879\n",
      "Mean BIC score: 66.359 Â± 5.441\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Mean accuracy: 0.733 Â± 0.153\n",
      "Mean precision: 0.775 Â± 0.130\n",
      "Mean recall: 0.880 Â± 0.165\n",
      "Mean f1 score: 0.814 Â± 0.119\n",
      "Mean MCC score: 0.346 Â± 0.395\n",
      "Mean AIC score: 76.903 Â± 2.907\n",
      "Mean BIC score: 69.678 Â± 2.766\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Mean accuracy: 0.783 Â± 0.150\n",
      "Mean precision: 0.813 Â± 0.139\n",
      "Mean recall: 0.925 Â± 0.160\n",
      "Mean f1 score: 0.849 Â± 0.111\n",
      "Mean MCC score: 0.471 Â± 0.416\n",
      "Mean AIC score: 73.693 Â± 3.442\n",
      "Mean BIC score: 66.592 Â± 3.146\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Mean accuracy: 0.700 Â± 0.145\n",
      "Mean precision: 0.763 Â± 0.137\n",
      "Mean recall: 0.850 Â± 0.166\n",
      "Mean f1 score: 0.788 Â± 0.106\n",
      "Mean MCC score: 0.263 Â± 0.410\n",
      "Mean AIC score: 134.026 Â± 4.196\n",
      "Mean BIC score: 120.865 Â± 3.950\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Mean accuracy: 0.817 Â± 0.157\n",
      "Mean precision: 0.867 Â± 0.146\n",
      "Mean recall: 0.900 Â± 0.166\n",
      "Mean f1 score: 0.866 Â± 0.118\n",
      "Mean MCC score: 0.579 Â± 0.412\n",
      "Mean AIC score: 94.489 Â± 1.484\n",
      "Mean BIC score: 85.201 Â± 1.243\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Accuracy: 0.783\n",
      "Precision: 0.804\n",
      "Recall: 0.902\n",
      "f1 score: 0.851\n",
      "MCC score: 0.472\n",
      "Mean AIC score: 68.304 Â± 1.519\n",
      "Mean BIC score: 1.038 Â± 0.858\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Accuracy: 0.800\n",
      "Precision: 0.809\n",
      "Recall: 0.927\n",
      "f1 score: 0.864\n",
      "MCC score: 0.512\n",
      "Mean AIC score: 81.805 Â± 2.274\n",
      "Mean BIC score: 1.138 Â± 1.009\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Accuracy: 0.750\n",
      "Precision: 0.760\n",
      "Recall: 0.927\n",
      "f1 score: 0.835\n",
      "MCC score: 0.369\n",
      "Mean AIC score: 121.294 Â± 2.167\n",
      "Mean BIC score: 1.161 Â± 1.059\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Accuracy: 0.800\n",
      "Precision: 0.837\n",
      "Recall: 0.878\n",
      "f1 score: 0.857\n",
      "MCC score: 0.526\n",
      "Mean AIC score: 73.595 Â± 1.674\n",
      "Mean BIC score: 0.928 Â± 1.166\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Accuracy: 0.733\n",
      "Precision: 0.778\n",
      "Recall: 0.854\n",
      "f1 score: 0.814\n",
      "MCC score: 0.352\n",
      "Mean AIC score: 132.030 Â± 2.065\n",
      "Mean BIC score: 1.263 Â± 1.357\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Accuracy: 0.833\n",
      "Precision: 0.860\n",
      "Recall: 0.902\n",
      "f1 score: 0.881\n",
      "MCC score: 0.606\n",
      "Mean AIC score: 95.368 Â± 2.193\n",
      "Mean BIC score: 0.834 Â± 0.993\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AIC_LOO_SVM = []\n",
    "\n",
    "# calculate the other classification metrics\n",
    "print('Support Vector Machine Classifier, pipeline = Scaler, SVC')\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'Scaler+SVMClassifier',\n",
    "                                                                                        X = FSs[i], \n",
    "                                                                                        y = y_class,\n",
    "                                                                                        model_params=best_hyperparameters_SVMC_list[6*j+i],\n",
    "                                                                                        cross_validation_technique = CV_methods_strings[j])\n",
    "        print()\n",
    "        if CV_methods_strings[j] == 'loocv':\n",
    "            AIC_LOO_SVM.append(mean_metrics[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Decision Tree Classifier\n",
    "\n",
    "- Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.6500\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.7833\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.8500\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.9000\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.8667\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Best Cross-Validation Accuracy: 0.6667\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Best Cross-Validation Accuracy: 0.8833\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Best Cross-Validation Accuracy: 0.8667\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Accuracy: 0.9333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid \n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 8, 10, 20],\n",
    "    'min_samples_split': [2, 5, 8, 10, 15, 20]\n",
    "}\n",
    "\n",
    "best_hyperparameters_DTC_list = []\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_DTC_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate other classification evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Mean accuracy: 0.850 Â± 0.117\n",
      "Mean precision: 0.887 Â± 0.119\n",
      "Mean recall: 0.925 Â± 0.160\n",
      "Mean f1 score: 0.888 Â± 0.098\n",
      "Mean MCC score: 0.674 Â± 0.285\n",
      "Mean AIC score: 60.380 Â± 46.420\n",
      "Mean BIC score: 59.443 Â± 46.369\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Mean accuracy: 0.650 Â± 0.138\n",
      "Mean precision: 0.767 Â± 0.161\n",
      "Mean recall: 0.780 Â± 0.236\n",
      "Mean f1 score: 0.734 Â± 0.149\n",
      "Mean MCC score: 0.166 Â± 0.364\n",
      "Mean AIC score: 58.340 Â± 46.227\n",
      "Mean BIC score: 57.403 Â± 46.253\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Mean accuracy: 0.783 Â± 0.150\n",
      "Mean precision: 0.847 Â± 0.158\n",
      "Mean recall: 0.875 Â± 0.168\n",
      "Mean f1 score: 0.843 Â± 0.115\n",
      "Mean MCC score: 0.475 Â± 0.405\n",
      "Mean AIC score: 49.266 Â± 47.670\n",
      "Mean BIC score: 48.245 Â± 47.647\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Mean accuracy: 0.883 Â± 0.130\n",
      "Mean precision: 0.910 Â± 0.111\n",
      "Mean recall: 0.925 Â± 0.115\n",
      "Mean f1 score: 0.913 Â± 0.098\n",
      "Mean MCC score: 0.747 Â± 0.290\n",
      "Mean AIC score: 41.499 Â± 35.207\n",
      "Mean BIC score: 40.291 Â± 35.256\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Mean accuracy: 0.850 Â± 0.117\n",
      "Mean precision: 0.910 Â± 0.111\n",
      "Mean recall: 0.880 Â± 0.121\n",
      "Mean f1 score: 0.888 Â± 0.088\n",
      "Mean MCC score: 0.681 Â± 0.262\n",
      "Mean AIC score: 48.780 Â± 35.299\n",
      "Mean BIC score: 47.572 Â± 35.337\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Mean accuracy: 0.900 Â± 0.111\n",
      "Mean precision: 0.920 Â± 0.098\n",
      "Mean recall: 0.950 Â± 0.150\n",
      "Mean f1 score: 0.922 Â± 0.100\n",
      "Mean MCC score: 0.803 Â± 0.201\n",
      "Mean AIC score: 53.698 Â± 48.651\n",
      "Mean BIC score: 52.656 Â± 48.520\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Accuracy: 0.867\n",
      "Precision: 0.867\n",
      "Recall: 0.951\n",
      "f1 score: 0.907\n",
      "MCC score: 0.683\n",
      "Mean AIC score: 15.630 Â± 22.060\n",
      "Mean BIC score: 7.430 Â± 21.560\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Accuracy: 0.667\n",
      "Precision: 0.756\n",
      "Recall: 0.756\n",
      "f1 score: 0.756\n",
      "MCC score: 0.230\n",
      "Mean AIC score: 42.629 Â± 34.434\n",
      "Mean BIC score: 24.029 Â± 33.982\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Accuracy: 0.800\n",
      "Precision: 0.809\n",
      "Recall: 0.927\n",
      "f1 score: 0.864\n",
      "MCC score: 0.512\n",
      "Mean AIC score: 17.865 Â± 21.573\n",
      "Mean BIC score: 7.631 Â± 21.505\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Accuracy: 0.883\n",
      "Precision: 0.905\n",
      "Recall: 0.927\n",
      "f1 score: 0.916\n",
      "MCC score: 0.727\n",
      "Mean AIC score: 18.054 Â± 19.673\n",
      "Mean BIC score: 6.121 Â± 19.892\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Accuracy: 0.867\n",
      "Precision: 0.884\n",
      "Recall: 0.927\n",
      "f1 score: 0.905\n",
      "MCC score: 0.685\n",
      "Mean AIC score: 24.245 Â± 24.991\n",
      "Mean BIC score: 9.612 Â± 24.505\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Accuracy: 0.933\n",
      "Precision: 0.911\n",
      "Recall: 1.000\n",
      "f1 score: 0.953\n",
      "MCC score: 0.848\n",
      "Mean AIC score: 13.215 Â± 18.695\n",
      "Mean BIC score: 4.948 Â± 17.947\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AIC_LOO_DT = []\n",
    "\n",
    "print('Decision Tree Classifier')\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        (mean_metrics, std_metrics) = Classifier_calculate_metrics_FINAL2(model_str = 'DecisionTreeClassifier',\n",
    "                                                                                        X = FSs[i], \n",
    "                                                                                        y = y_class,\n",
    "                                                                                        model_params=best_hyperparameters_DTC_list[6*j+i],\n",
    "                                                                                        cross_validation_technique = CV_methods_strings[j])\n",
    "        print()\n",
    "        if CV_methods_strings[j] == 'loocv':\n",
    "            AIC_LOO_DT.append(mean_metrics[5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. k-Nearest Neighbors Classifier\n",
    "\n",
    "- Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Nighbors Classifier\n",
      "###### Using the  Stratified 10-Fold  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 9}\n",
      "Best Cross-Validation Accuracy: 0.7500\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 9}\n",
      "Best Cross-Validation Accuracy: 0.7333\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 3}\n",
      "Best Cross-Validation Accuracy: 0.6833\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 5}\n",
      "Best Cross-Validation Accuracy: 0.7667\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 3}\n",
      "Best Cross-Validation Accuracy: 0.7000\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 5}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "\n",
      "###### Using the  Leave One Out  cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 5}\n",
      "Best Cross-Validation Accuracy: 0.8000\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 9}\n",
      "Best Cross-Validation Accuracy: 0.7167\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 9}\n",
      "Best Cross-Validation Accuracy: 0.7000\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 5}\n",
      "Best Cross-Validation Accuracy: 0.7500\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 5}\n",
      "Best Cross-Validation Accuracy: 0.7500\n",
      "\n",
      "Using the feature selection  X_ANOVACorr :\n",
      "Best Hyperparameters: {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 3}\n",
      "Best Cross-Validation Accuracy: 0.8333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model, scaler and pipeline\n",
    "model = KNeighborsClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pipeline_kNN = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('KNN', model)\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid \n",
    "param_grid = {\n",
    "    'KNN__n_neighbors': [3, 5, 7, 9],\n",
    "    'KNN__metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "best_hyperparameters_kNN_list = []\n",
    "\n",
    "print('k-Nearest Nighbors Classifier')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the ', CV_methods_strings_list[j], ' cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=pipeline_kNN, param_grid=param_grid, cv = CV_methods_list[j], scoring='accuracy')\n",
    "        grid_search.fit(FSs[i], y_class)\n",
    "        best_hyperparameters_kNN_list.append(grid_search.best_params_)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Comparing Classification models using the Akaike weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.49586916e-155 2.33352514e-004 1.42583124e-002 2.83808305e-033\n",
      " 0.00000000e+000 1.96025644e-316 8.57987373e-212 0.00000000e+000\n",
      " 1.75988411e-100 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 7.21130642e-013 8.44196112e-016 2.24615574e-024 5.11987590e-014\n",
      " 1.04751029e-026 9.57849190e-019 7.12420596e-022 6.65711216e-022\n",
      " 3.47861437e-040 3.08032117e-025 6.47682691e-047 1.66641411e-025\n",
      " 1.97752610e-001 2.71223285e-007 6.46878682e-002 5.88511113e-002\n",
      " 2.66311333e-003 6.61553361e-001]\n"
     ]
    }
   ],
   "source": [
    "AIC_LOO_all_FSsModels = AIC_LOO_RFC + AIC_LOO_XGBoost + AIC_LOO_SVM + AICs_LOO_GNB + AIC_LOO_DT\n",
    "\n",
    "min_AIC_LOO = min(AIC_LOO_all_FSsModels)\n",
    "AIC_LOO_all_FSsModels = np.array(AIC_LOO_all_FSsModels)\n",
    "\n",
    "den = np.sum(np.exp(-(AIC_LOO_all_FSsModels - min_AIC_LOO)/2))\n",
    "\n",
    "# Compute Akaike weights\n",
    "Akaike_weights = np.exp(-(AIC_LOO_all_FSsModels - min_AIC_LOO) / 2) / den\n",
    "print(Akaike_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1-6: Random Forest Classifier\n",
    "- 7-12: XGBoost classifier\n",
    "- 12-18: SVM classifier\n",
    "- 18-24: Gaussian Naive Bayes classifier\n",
    "- 24-30: Decision tree classifier\n",
    "\n",
    "Model with highest weight: ANOVA+Decision tree: 0.662"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common for all regression models\n",
    "cv1 = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "cv2 = LeaveOneOut()\n",
    "\n",
    "CV_methods_list = [cv1, cv2]\n",
    "CV_methods_strings_list = ['10-Fold', 'Leave One Out']\n",
    "CV_methods_strings = ['skfcv', 'loocv']\n",
    "\n",
    "y = y.values.ravel()\n",
    "\n",
    "FSs = [X_FS1_RF, X_CCCB1, X_CCCB1_1, X_CCCB2, X_CCCB2_1, X_PearsonCorr]\n",
    "FSs_strings = ['X_FS1_RF', 'X_CCCB1', 'X_CCCB1_1', 'X_CCCB2', 'X_CCCB2_1', 'X_PearsonCorr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the 10-Fold cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best Cross-Validation Mean Absolute Error: -16.581\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Cross-Validation Mean Absolute Error: -20.112\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best Cross-Validation Mean Absolute Error: -19.818\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Mean Absolute Error: -19.190\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': 8, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation Mean Absolute Error: -19.551\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'max_depth': 8, 'min_samples_split': 8, 'n_estimators': 200}\n",
      "Best Cross-Validation Mean Absolute Error: -17.561\n",
      "\n",
      "###### Using the Leave One Out cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best Cross-Validation Mean Absolute Error: -15.889\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 3}\n",
      "Best Cross-Validation Mean Absolute Error: -18.011\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': 8, 'min_samples_split': 5, 'n_estimators': 4}\n",
      "Best Cross-Validation Mean Absolute Error: -18.430\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5}\n",
      "Best Cross-Validation Mean Absolute Error: -18.036\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15, 'n_estimators': 200}\n",
      "Best Cross-Validation Mean Absolute Error: -18.859\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 15, 'n_estimators': 10}\n",
      "Best Cross-Validation Mean Absolute Error: -16.176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [3, 4, 5, 10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 8, 10, 20],\n",
    "    'min_samples_split': [2, 5, 8, 10, 15, 20]\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(random_state= 42)\n",
    "\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the', CV_methods_strings_list[j], 'cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=CV_methods_list[j], scoring='neg_mean_absolute_error')\n",
    "\n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(FSs[i], y)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Mean Absolute Error: {grid_search.best_score_:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Using the 10-Fold cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'reg_lambda': 0}\n",
      "Best Cross-Validation Accuracy: -20.070\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 10, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -19.846\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -22.206\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -21.155\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 5, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -22.357\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -18.920\n",
      "\n",
      "###### Using the Leave One Out cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -18.158\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 10, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -19.778\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -20.296\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 200, 'reg_lambda': 0}\n",
      "Best Cross-Validation Accuracy: -18.679\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 100, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -21.837\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 10, 'reg_lambda': 1}\n",
      "Best Cross-Validation Accuracy: -18.927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight_1 = num_insuff_samples/num_sufficient_samples\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [3, 4, 5, 10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'reg_lambda': [0,1]\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state= 42)\n",
    "\n",
    "for j in range(len(CV_methods_strings)):\n",
    "    print('###### Using the', CV_methods_strings_list[j], 'cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        # Clean feature names\n",
    "        FSs[i] = clean_column_names(FSs[i])\n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=CV_methods_list[j], scoring='neg_mean_absolute_error')\n",
    "\n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(FSs[i], y)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Linear Regression\n",
      "Using the 10-Fold cross validation:\n",
      "\n",
      "Using the dataset  X_FS1_RF :\n",
      "Mean MAE score: -22.684\n",
      "\n",
      "Using the dataset  X_CCCB1 :\n",
      "Mean MAE score: -27.335\n",
      "\n",
      "Using the dataset  X_CCCB1_1 :\n",
      "Mean MAE score: -26.535\n",
      "\n",
      "Using the dataset  X_CCCB2 :\n",
      "Mean MAE score: -22.779\n",
      "\n",
      "Using the dataset  X_CCCB2_1 :\n",
      "Mean MAE score: -24.526\n",
      "\n",
      "Using the dataset  X_PearsonCorr :\n",
      "Mean MAE score: -16.424\n",
      "\n",
      "Using the Leave One Out cross validation:\n",
      "\n",
      "Using the dataset  X_FS1_RF :\n",
      "Mean MAE score: -22.993\n",
      "\n",
      "Using the dataset  X_CCCB1 :\n",
      "Mean MAE score: -21.563\n",
      "\n",
      "Using the dataset  X_CCCB1_1 :\n",
      "Mean MAE score: -22.706\n",
      "\n",
      "Using the dataset  X_CCCB2 :\n",
      "Mean MAE score: -20.827\n",
      "\n",
      "Using the dataset  X_CCCB2_1 :\n",
      "Mean MAE score: -18.529\n",
      "\n",
      "Using the dataset  X_PearsonCorr :\n",
      "Mean MAE score: -16.796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model_lr  = LinearRegression()\n",
    "\n",
    "print('Results for Linear Regression')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('Using the', CV_methods_strings_list[j],'cross validation:')\n",
    "    for i in range(len(FSs)):\n",
    "        # Get cross validation scores for each CV run\n",
    "        scores = cross_val_score(model_lr, FSs[i], y, cv=CV_methods_list[j], scoring='neg_mean_absolute_error')\n",
    "\n",
    "        # Print the scores and the average score\n",
    "        print()\n",
    "        print('Using the dataset ', FSs_strings[i],':')\n",
    "        print(f\"Mean MAE score: {np.mean(scores):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree Regressor\n",
      "###### Using the 10-Fold cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 20}\n",
      "Best Cross-Validation Mean Absolute Error: -21.251\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -21.628\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -22.996\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 5}\n",
      "Best Cross-Validation Mean Absolute Error: -22.931\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -22.613\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 20}\n",
      "Best Cross-Validation Mean Absolute Error: -21.048\n",
      "\n",
      "\n",
      "###### Using the Leave One Out cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 20}\n",
      "Best Cross-Validation Mean Absolute Error: -18.034\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -21.981\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Best Cross-Validation Mean Absolute Error: -20.951\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -22.762\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 20}\n",
      "Best Cross-Validation Mean Absolute Error: -26.373\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_split': 15}\n",
      "Best Cross-Validation Mean Absolute Error: -17.438\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model and hyperparameter grid\n",
    "model_DecisionTreeRegressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 8, 10, 20],\n",
    "    'min_samples_split': [2, 5, 8, 10, 15, 20]\n",
    "}\n",
    "\n",
    "print('Results for Decision Tree Regressor')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the', CV_methods_strings_list[j], 'cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(estimator=model_DecisionTreeRegressor, param_grid=param_grid, cv=CV_methods_list[j], scoring='neg_mean_absolute_error')\n",
    "\n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(FSs[i], y)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Mean Absolute Error: {grid_search.best_score_:.3f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Support Vector Regressor\n",
      "###### Using the 10-Fold cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -19.259\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -19.450\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -17.719\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -18.083\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -17.051\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -16.228\n",
      "\n",
      "\n",
      "###### Using the Leave One Out cross validation to find the best hyperparameters ######\n",
      "Using the feature selection  X_FS1_RF :\n",
      "Best Hyperparameters: {'svr__C': 1000, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -18.667\n",
      "\n",
      "Using the feature selection  X_CCCB1 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -18.380\n",
      "\n",
      "Using the feature selection  X_CCCB1_1 :\n",
      "Best Hyperparameters: {'svr__C': 10, 'svr__gamma': 1, 'svr__kernel': 'linear'}\n",
      "Best Cross-Validation Mean Absolute Error: -17.325\n",
      "\n",
      "Using the feature selection  X_CCCB2 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -17.395\n",
      "\n",
      "Using the feature selection  X_CCCB2_1 :\n",
      "Best Hyperparameters: {'svr__C': 100, 'svr__gamma': 0.01, 'svr__kernel': 'rbf'}\n",
      "Best Cross-Validation Mean Absolute Error: -17.101\n",
      "\n",
      "Using the feature selection  X_PearsonCorr :\n",
      "Best Hyperparameters: {'svr__C': 1000, 'svr__gamma': 1, 'svr__kernel': 'linear'}\n",
      "Best Cross-Validation Mean Absolute Error: -15.148\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model and pipeline\n",
    "model_SVR = SVR()\n",
    "pipeline_SVR = Pipeline([\n",
    "    ('scaler', standard_scaler),\n",
    "    ('svr', model_SVR)\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'svr__C': [0.1, 1, 10, 100, 1000],\n",
    "    'svr__kernel': ['linear','rbf'],\n",
    "    'svr__gamma': [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "print('Results for Support Vector Regressor')\n",
    "for j in range(len(CV_methods_list)):\n",
    "    print('###### Using the', CV_methods_strings_list[j], 'cross validation to find the best hyperparameters ######')\n",
    "    for i in range(len(FSs)):\n",
    "        # Initialize GridSearchCV\n",
    "        grid_search = GridSearchCV(estimator=pipeline_SVR, param_grid=param_grid, cv=CV_methods_list[j], scoring='neg_mean_absolute_error')\n",
    "\n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(FSs[i], y)\n",
    "\n",
    "        # Print best parameters and best score\n",
    "        print('Using the feature selection ', FSs_strings[i], ':')\n",
    "        print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best Cross-Validation Mean Absolute Error: {grid_search.best_score_:.3f}\")\n",
    "        print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
